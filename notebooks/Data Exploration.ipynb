{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview\n",
    "\n",
    "Before we dig too deeply into the data we should understand the data format a little bit better.\n",
    "\n",
    "At its core, the OpenSNP  has 4 components each . A CSV file, several text files, several image files, and another CSV file corresponding to the image files. We will be ignoring the image data during this exploration.\n",
    "\n",
    "The CSV file is delimitted by ';' and there are a number of rows, each corresponding to a question that a user answered. Each row corresponds to a different user. User's do not need to answer any question, in fact most of them do not. To add further complication, the answers are primarily free-form and not normalized to any standard.\n",
    "\n",
    "Each text file corresponds to a single user (and a single user may have more than 1 text file associated with them). The text files contain a list of genetic variants that were identified in the user's genetic data.\n",
    "\n",
    "The genetic variant information in this dataset was uploaded by users and collected and analyzed through various services such as [23andMe](https://www.23andme.com/), [deCODEme](https://www.decode.com/decode-launches-decodeme/), or [FamilyTreeDNA](https://www.familytreedna.com/) (the source is listed in the `.txt` files and the survey information was collected through [OpenSNP](https://www.opensnp.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/phenotypes_201811100342.csv\n",
      "../data/picture_phenotypes_201811100342.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/*txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4708\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/* | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the file that we are looking at\n",
    "data_file = \"../data/phenotypes_201811100342.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the column name we are interested\n",
    "col_name_myers = 'Myers-Briggs Type Indicator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV into a dataframe\n",
    "df = pd.read_csv(data_file, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Exploration\n",
    "Now that we understand the data and we have loaded it into a dataframe, we will take a look at it.\n",
    "\n",
    "Let's start by looking at the number os users, the number of questions answered, and then determine how many people answered each question.\n",
    "\n",
    "## Summary CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the row, column count\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 user submissions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out each column by alphabetical order\n",
    "for column in sorted(df.columns):\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a count of each column\n",
    "(df != '-').sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the sum, only for the columns we care about\n",
    "(df != '-').sum(axis = 0, skipna = True)[col_name_myers]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here! The website said there were 299 entries.\n",
    "\n",
    "Upon closer inspection, we see that the website has a setion labeled \"Already answered on previous submission.\" That probably acounts for the missing ten, and that would likely indicate thate we have 10 users who submitted twice. We'll look into this later.\n",
    "\n",
    "For now let's plot some of the data out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the dataframe with a count of how many answers were given\n",
    "count_df = (df != '-').sum(axis = 1, skipna = True)\n",
    "df.insert(1, column='count', value=count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual User Files\n",
    "\n",
    "Now that we have taken a look at the summary file, let's take a look at a single user file and then see how we can load all relevant user files into a dataframe for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
